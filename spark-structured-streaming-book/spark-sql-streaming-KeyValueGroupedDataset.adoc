== [[KeyValueGroupedDataset]] KeyValueGroupedDataset -- Streaming Aggregation

`KeyValueGroupedDataset` represents a *grouped dataset* as a result of link:spark-sql-streaming-Dataset-operators.adoc#groupByKey[groupByKey] operator (that aggregates records by a grouping function).

[source, scala]
----
// Dataset[T]
groupByKey(func: T => K): KeyValueGroupedDataset[K, T]
----

`KeyValueGroupedDataset` works for batch and streaming aggregations, but shines the most when used for *streaming aggregation* (with streaming Datasets).

[source, scala]
----
import java.sql.Timestamp
scala> val numGroups = spark.
  readStream.
  format("rate").
  load.
  as[(Timestamp, Long)].
  groupByKey { case (time, value) => value % 2 }
numGroups: org.apache.spark.sql.KeyValueGroupedDataset[Long,(java.sql.Timestamp, Long)] = org.apache.spark.sql.KeyValueGroupedDataset@616c1605

import org.apache.spark.sql.streaming.Trigger
import scala.concurrent.duration._
numGroups.
  mapGroups { case(group, values) => values.size }.
  writeStream.
  format("console").
  trigger(Trigger.ProcessingTime(10.seconds)).
  start

-------------------------------------------
Batch: 0
-------------------------------------------
+-----+
|value|
+-----+
+-----+

-------------------------------------------
Batch: 1
-------------------------------------------
+-----+
|value|
+-----+
|    3|
|    2|
+-----+

-------------------------------------------
Batch: 2
-------------------------------------------
+-----+
|value|
+-----+
|    5|
|    5|
+-----+

// Eventually...
spark.streams.active.foreach(_.stop)
----

The most prestigious use case of `KeyValueGroupedDataset` however is *stateful streaming aggregation* that allows for accumulating *streaming state* (by means of link:spark-sql-streaming-GroupState.adoc[GroupState]) using <<mapGroupsWithState, mapGroupsWithState>> and the more advanced <<flatMapGroupsWithState, flatMapGroupsWithState>> operators.

[[operators]]
.KeyValueGroupedDataset's Operators
[cols="1,2",options="header",width="100%"]
|===
| Operator
| Description

| <<agg, agg>>
|

| <<cogroup, cogroup>>
|

| <<count, count>>
|

| <<flatMapGroups, flatMapGroups>>
|

| [[flatMapGroupsWithState]] link:spark-sql-streaming-KeyValueGroupedDataset-flatMapGroupsWithState.adoc[flatMapGroupsWithState]
a| Creates a `Dataset` with link:spark-sql-streaming-FlatMapGroupsWithState.adoc#apply[FlatMapGroupsWithState] logical operator

NOTE: The difference between `flatMapGroupsWithState` and <<mapGroupsWithState, mapGroupsWithState>> is the state function that generates zero or more elements (that are in turn the rows in the result `Dataset`).

| <<keyAs, keyAs>>
|

| <<keys, keys>>
|

| <<mapGroups, mapGroups>>
|

| [[mapGroupsWithState]] link:spark-sql-streaming-KeyValueGroupedDataset-mapGroupsWithState.adoc[mapGroupsWithState]
a| Creates a `Dataset` with link:spark-sql-streaming-FlatMapGroupsWithState.adoc#apply[FlatMapGroupsWithState] logical operator

NOTE: The difference between `mapGroupsWithState` and <<flatMapGroupsWithState, flatMapGroupsWithState>> is the state function that generates exactly one element (that is in turn the row in the result `Dataset`).

| <<mapValues, mapValues>>
|

| <<queryExecution, queryExecution>>
|

| <<reduceGroups, reduceGroups>>
|
|===

=== [[creating-instance]] Creating KeyValueGroupedDataset Instance

`KeyValueGroupedDataset` takes the following when created:

* [[kEncoder]] `Encoder` for keys
* [[vEncoder]] `Encoder` for values
* [[queryExecution]] `QueryExecution`
* [[dataAttributes]] Data attributes
* [[groupingAttributes]] Grouping attributes
