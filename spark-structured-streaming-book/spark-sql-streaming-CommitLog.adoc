== [[CommitLog]] CommitLog -- HDFSMetadataLog for Batch Completion Log

`CommitLog` is a <<spark-sql-streaming-HDFSMetadataLog.adoc#, HDFSMetadataLog>> with metadata as regular text (i.e. `String`).

NOTE: <<spark-sql-streaming-HDFSMetadataLog.adoc#, HDFSMetadataLog>> is a `MetadataLog` that uses Hadoop HDFS for a reliable storage.

`CommitLog` is <<creating-instance, created>> along with <<spark-sql-streaming-StreamExecution.adoc#commitLog, StreamExecution>>.

=== [[add-batchId]] `add` Method

[source, scala]
----
add(batchId: Long): Unit
----

`add`...FIXME

NOTE: `add` is used when...FIXME

=== [[add-batchId-metadata]] `add` Method

[source, scala]
----
add(batchId: Long, metadata: String): Boolean
----

NOTE: `add` is part of <<spark-sql-streaming-MetadataLog.adoc#add, MetadataLog Contract>> to...FIXME.

`add`...FIXME

=== [[serialize]] `serialize` Method

[source, scala]
----
serialize(metadata: String, out: OutputStream): Unit
----

NOTE: `serialize` is part of <<spark-sql-streaming-HDFSMetadataLog.adoc#serialize, HDFSMetadataLog Contract>> to write a metadata in serialized format.

`serialize` writes out the version prefixed with `v` on a single line (e.g. `v1`) followed by the empty JSON (i.e. `{}`).

NOTE: The version in Spark 2.2 is *1* with the charset being *UTF-8*.

NOTE: `serialize` always writes an empty JSON as the name of the files gives the meaning.

```
$ ls -tr [checkpoint-directory]/commits
0 1 2 3 4 5 6 7 8 9

$ cat [checkpoint-directory]/commits/8
v1
{}
```

=== [[deserialize]] `deserialize` Method

[source, scala]
----
deserialize(in: InputStream): String
----

NOTE: `deserialize` is part of <<spark-sql-streaming-HDFSMetadataLog.adoc#deserialize, HDFSMetadataLog Contract>> to...FIXME.

`deserialize`...FIXME

=== [[creating-instance]] Creating CommitLog Instance

`CommitLog` takes the following when created:

* [[sparkSession]] `SparkSession`
* [[path]] Path of the metadata log directory
